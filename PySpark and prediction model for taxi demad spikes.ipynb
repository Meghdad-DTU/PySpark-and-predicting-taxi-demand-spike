{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "Imagine that you are an NYC taxi fleet manager. At each 15 minutes, you goal is to make sure your company has enough cars for very big spikes in demand across the city (like above 90 percentile). If you detect some very big spike in a specific area, you coordinate with the cars in the neighbourhood to go there. Here, let's assume that area 1 is the only truly important for you. The dataset includes number of pickups in Zone 1 and its neighbouring zones alongside their first and second lagged time. Weather information, day time and week time are also included.\n",
    "### Aim: \n",
    "At each 15 minutes time interval, predict whether the next time interval will have a demand spike (\"stress\"). We want to compare 4 different classifiers including logistic regression, Decision tree, Random forest and Gradient boosted tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(\"/home/meghdad/spark-2.4.5-bin-hadoop2.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName(\"NYCtaxiSpike\").getOrCreate()\n",
    "df=spark.read.csv(\"NYC_taxis_weather_2016_with_dummies.csv\",header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows and columns are:  (17472, 22)\n",
      "root\n",
      " |-- datetime: timestamp (nullable = true)\n",
      " |-- pickups1: integer (nullable = true)\n",
      " |-- pickups17_lag1: double (nullable = true)\n",
      " |-- pickups17_lag2: double (nullable = true)\n",
      " |-- pickups1_lag1: double (nullable = true)\n",
      " |-- pickups1_lag2: double (nullable = true)\n",
      " |-- pickups21_lag1: double (nullable = true)\n",
      " |-- pickups21_lag2: double (nullable = true)\n",
      " |-- pickups28_lag1: double (nullable = true)\n",
      " |-- pickups28_lag2: double (nullable = true)\n",
      " |-- temp: double (nullable = true)\n",
      " |-- prcp: double (nullable = true)\n",
      " |-- fog: integer (nullable = true)\n",
      " |-- rain_drizzle: integer (nullable = true)\n",
      " |-- time_of_day_afternoon: integer (nullable = true)\n",
      " |-- time_of_day_afternoon rush: integer (nullable = true)\n",
      " |-- time_of_day_evening: integer (nullable = true)\n",
      " |-- time_of_day_lunch time: integer (nullable = true)\n",
      " |-- time_of_day_morning: integer (nullable = true)\n",
      " |-- time_of_day_morning rush: integer (nullable = true)\n",
      " |-- time_of_day_night: integer (nullable = true)\n",
      " |-- is_weekend: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of rows and columns are: \", (df.count(),len(df.columns)))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## use approxquantile method which implements Greenwald-Khanna-algorithm\n",
    "## 0.001 is a relative error. the lower the number the more accurate results \n",
    "# and more expensive computation\n",
    "stress_treshold=df.approxQuantile(\"pickups1\",[0.90],0.001)[0]\n",
    "stress_treshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|spike|count|\n",
      "+-----+-----+\n",
      "|    1| 1748|\n",
      "|    0|15724|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## creat a new column that is 1 when it is a \"stress\" scenario and 0 when it is not\n",
    "from pyspark.sql.functions import when, col \n",
    "df=df.withColumn(\"spike\",when(col(\"pickups1\")>stress_treshold,1).otherwise(0))\n",
    "df.groupBy(\"spike\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|spike|            features|\n",
      "+-----+--------------------+\n",
      "|    0|(20,[0,1,2,3,4,5,...|\n",
      "|    0|(20,[0,1,2,3,4,5,...|\n",
      "|    0|(20,[0,1,2,3,4,5,...|\n",
      "|    1|(20,[0,1,2,3,4,5,...|\n",
      "|    1|(20,[0,1,2,3,4,5,...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "features=df.columns[2:-1]\n",
    "assembler=VectorAssembler(inputCols=features,outputCol=\"features\")\n",
    "final_data=assembler.transform(df).select(\"spike\",\"features\")\n",
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (LogisticRegression,DecisionTreeClassifier,\n",
    "                                       RandomForestClassifier,GBTClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    " \n",
    "\n",
    "## create initial classifiers\n",
    "lr=LogisticRegression(labelCol=\"spike\",featuresCol=\"features\")\n",
    "dtc=DecisionTreeClassifier(labelCol=\"spike\",featuresCol=\"features\")\n",
    "rfc=RandomForestClassifier(labelCol=\"spike\",featuresCol=\"features\")\n",
    "gbt=GBTClassifier(labelCol=\"spike\",featuresCol=\"features\")\n",
    "\n",
    "## evaluate models\n",
    "## metricName can be set as f1,weightedPrecision,weightedRecall and accuracy\n",
    "evaluator=MulticlassClassificationEvaluator(labelCol=\"spike\",predictionCol=\"prediction\",\n",
    "                                            metricName=\"accuracy\")\n",
    "\n",
    "## since grid search is computationally expensive we perfom cross validation without it\n",
    "## one easy solution is to provide the parameters you want to use\n",
    "paramGrid_lr=ParamGridBuilder().addGrid(lr.maxIter,[100]).build()\n",
    "paramGrid_dtc=ParamGridBuilder().addGrid(dtc.impurity,[\"gini\"]).build()\n",
    "paramGrid_rfc=ParamGridBuilder().addGrid(rfc.numTrees,[150]).build()\n",
    "paramGrid_gbt=ParamGridBuilder().addGrid(gbt.maxIter,[25]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[lr,dtc,rfc,gbt]\n",
    "paramGrids=[paramGrid_lr,paramGrid_dtc,paramGrid_rfc,paramGrid_gbt]\n",
    "names=[\"Logistic regression\",\"Decision tree\",\"Random forest\",\"Gradient boosting\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avarage accuracy of Logistic regression model is :0.9531042016971911\n",
      "Avarage accuracy of Decision tree model is :0.9470960436429154\n",
      "Avarage accuracy of Random forest model is :0.9502260030538972\n",
      "Avarage accuracy of Gradient boosting model is :0.9500213721666722\n"
     ]
    }
   ],
   "source": [
    "for estimator, paramGrid, name in zip(estimators,paramGrids, names):\n",
    "    ## create 3-fold cross validation\n",
    "    cross_val=CrossValidator(estimator=estimator,\n",
    "                         estimatorParamMaps=paramGrid,\n",
    "                         evaluator=evaluator,\n",
    "                         numFolds=3)\n",
    "    cvModel=cross_val.fit(final_data)\n",
    "    ## extract average metrics \n",
    "    accuracy_matrix=cvModel.avgMetrics\n",
    "    ## calcualte average accuracy\n",
    "    SUM=0\n",
    "    for x in accuracy_matrix:\n",
    "        SUM=x+SUM\n",
    "    average_accuracy=SUM/len(cvModel.avgMetrics)\n",
    "    print(\"Avarage accuracy of \"+name+\" model is :\"+ str(average_accuracy) )     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
